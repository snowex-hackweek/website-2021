{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microstructure Tutorial\n",
    "\n",
    "by Mike Durand, School of Earth Sciences and Byrd Polar & Climate Research Center durand.8@osu.edu\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this tutorial you should be able to...\n",
    "\n",
    "* Explain why microstructure is important for remote sensing\n",
    "* Define measures of microstructure, especially specific surface area\n",
    "* Access and visualize tree different microstructure measurements from SnowEx Grand Mesa 2020\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "Contributions from: Micah Johnson, Mike Durand, HP Marshall, Tate Meehan, Megan Mason, Scott Henderson. This relies heavily on the snowexsqul database and example scripts created by Micah Johnson.\n",
    "\n",
    "## Caveats\n",
    "\n",
    "The integrating sphere and the SMP data are published at NSIDC; you can read the pages there for documentation etc. However the microCT data are not yet published; please contact Lauren Farnsworth (lauren.b.farnsworth@usace.army.mil) for questions on the CT data.\n",
    "\n",
    "\n",
    "## Fun Facts About Snow Microstructure\n",
    "\n",
    "Snow microstructure plays a super important role in snow physics and snow remote sensing, so a lot of effort went towards measuring it in SnowEx 2020!\n",
    "\n",
    "There are several different quantities that are used to measure snow microstructure, including \"grain size\". Grain size measurements are challenging to make in a repeatable way, and are also challenging to relate to the physical quantities that control remote sensing measurements. In the last ~15 years or so, a lot of effort has gone into more objective ways to measure microstructure.\n",
    "\n",
    "Snow microstructure  governs response of remote sensing to snow cover for visible, near-infrared and high-frequency microwave wavelengths. See Figure 1, below, and read {cite:p}`Dozier2009`, for more information.\n",
    "\n",
    "<img src=\"images/dozier2009_fig2.jpg\" alt=\"dozier-figure\" width=\"400px\">\n",
    "\n",
    "<b>Snow microstructure governs visible and near-infrared reflectance. This is figure 2 from {cite:p}`Dozier2009`</b>\n",
    "\n",
    "Radar measurements such as those made by the Ku-band SWEARR instrument are also very sensitive to snow microstructure. \n",
    "\n",
    "<img src=\"images/modeled-swe-L-response.png\" alt=\"radar-figure\" width=\"400px\">\n",
    "\n",
    "<b>Modeled response of radar backscatter to SWE and single-scatter albedo (which in turn is a function of snow microstructure), based on a simple model suggested by {cite:p}`Ulaby2014`</b>\n",
    "\n",
    "Snow microstructure is super important to efforts to launch a Ku-band SAR to measure global snow water equivalent (SWE). An important area of research right now is exploring how to use estimates of microstructure (e.g. from snowpack evolution models) to improve SWE retrievals.\n",
    "\n",
    "Snow microstructure evolves through the season, and varies a lot with depth. Snow microstructure evolution is controlled by other snow properties, such as snow temperature, snow height and snow liquid water content. A really great resource on snow microstructure is Kelly Elder's recent talks:\n",
    "* [Snow Metamorphism](https://boisestate.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9a051fe4-db09-4f1d-92db-acd1003cc5cc)\n",
    "* [Snow Grain Identification](https://boisestate.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=136f7580-c1e2-4c55-ab33-acca003c23d6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SnowEx Microstructure Measurement Background\n",
    "\n",
    "### Basic Microstructure Definitions\n",
    "\n",
    "Microstructure definitions take a bit of getting used to. It's very easy to get confused. Specific surface area (SSA) is one of the most important quantity used to measure snow microstructure, so that's the focus here. Note that SSA is not the be-all and end-all, so there's a short table describing how to relate SSA to other quantities just below.  A couple of good reads on all of this is {cite:p}`Matzler2002` and {cite:p}`Matzl2010`.\n",
    "\n",
    "\n",
    "<img src=\"images/lowe_etal_2011_v2.png\" alt=\"lowe-figure\" width=\"400px\">\n",
    "\n",
    "<b>Coarse and fine snow microstructure revealed by microCT. The microCT snow renderings on the left are Figure 2 from {cite:p}`Lowe2011`. The colorbars indicate that fine-grained snow (a) has high SSA and low D<sub>eq</sub>, whereas coarse-grained snow (b) has low SSA and high D<sub>eq</sub>.</b>\n",
    "\n",
    "Use Figure 3 above to ground these definitions: SSA is the surface area of the ice-air interface, normalized in some way. Confusingly, SSA is defined in a couple of different ways in the literature: sometimes, surface area within a particular volume of interest (VOI) is normalized by the mass of the ice in the VOI. As defined in this way, SSA has units of length squared per mass, usually expressed as m<sup>2</sup>/kg. Instead of normalizing by mass, SSA is sometimes defined by normalizing by the volume of the VOI (this is SSA<sub>v</sub> in {cite:p}`Matzl2010`), and sometimes by normalizing by the volume of the ice in the VOI (this is SSA<sub>i</sub> in {cite:p}`Matzl2010`, and q in {cite:p}`Matzler2002`). Here let's just go with the first definition I mentioned:\n",
    "\n",
    "$$\n",
    "SSA = \\frac{\\text{Surface area of ice-air interface}}{\\text{Mass of ice}} \\quad\n",
    "$$ \n",
    "\n",
    "SSA tends to take values between 5 and 150 m<sup>2</sup>/kg: fresh, fine-grained snow has high SSA, and coarse snow has low SSA. Because it takes a little while for SSA values to become intuitive, a useful derived metric is the equivalent grain diameter (D<sub>eq</sub>; note that this is identical to D<sub>q</sub> in {cite:p}`Matzler2002`), which by definition is the diameter that a sphere would have if it had a particular value of SSA. This is a one-to-one relationship, so there are no assumptions involved.\n",
    "\n",
    "$$\n",
    "D_{eq} = \\frac{6}{SSA \\rho_i} \\quad\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationships of specific surface area to other metrics are given in this list if you're curious but otherwise just skip past this bit\n",
    "* Sometimes people refer to the \"optical grain diameter\", which is the same as D<sub>eq</sub>. The \"optical\" refers to {cite:p}`Grenfell1999`, who showed that any snow with a particular SSA had similar (not identical) radiative transfer properties regardless of particle shape in the visible and near-infrared parts of the spectrum. But note the same is not true in the microwave spectrum. \n",
    "* Autocorrelation length is usually one of two metrics that summarize the two-point microstructure autocorelation function of the three-dimensional ice-air matrix. Think of the probability that you change media (from ice to air or vice versa) as you move a certain distance within the snow microstructure. The length that defines the likelihood that you'll change media is (an approximation of the correlation length). SSA is by definition (with almost no assumptions) equal to the slope of the autocorrelation function at the origin. But microwave scattering is controlled by correlations at longer lags. For more check out {cite:p}`Matzler2002`. The lack of closing the loop between SSA and correlation length is a significant issue when we have measurements of SSA and microwaves as we do in SnowEx.\n",
    "* Geometric grain size is what we usually measure when we measure with a hand lens. You can try to relate it to SSA or corelation length, but it is not always possible, and will change with different observers. \n",
    "\n",
    "Time to stop this list but there are many other metrics as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microstructure Instruments\n",
    "\n",
    "Now that we know what we're trying to measure (SSA, or correlation length) how do we actually measure? let's talk just about three techniques used in SnowEx 2020 Grand Mesa. \n",
    "\n",
    "<img src=\"images/microCT.png\" alt=\"ct-figure\" width=\"800px\">\n",
    "\n",
    "<b>Left: Lauren Farnsworth transports microCT samples from field sites back to Grand Mesa Lodge in a cold storage container. Right: the microCT machine in the lab at CRREL.</b>\n",
    "\n",
    "Micro-computed tomography (microCT) is the only laboratory-based method used here, and it is the gold standard, although it does still come with caveats. The idea of microCT is to remove a sample of snow from a snow pit face, and either cast it with a compound such as diethyl pthalate that is still a liquid at 0Â° C, or preserve the same at a very cold temperature. Then the sample is sent back to the laboratory, and bombared with x-rays, similar to how you get x-rays to see if a bone is broken at the doctor. For much more on microCT, check out {cite:p}`Heggli2011`. microCT can be used to extract a ton of information about snow microstructure, including SSA, correlation length and many others. \n",
    "\n",
    "<img src=\"images/IntegratingSpheres.png\" alt=\"ct-figure\" width=\"800px\">\n",
    "\n",
    "<b>Left: Kehan Yang operates an IceCube unit at the Grand Mesa Lodge intercomparison snowpit. Top right: schematic showing the integrating sphere measurement principle, from {cite:p}`Gallet2009`. Bottom right: snow in the IceCube sampling container, from {cite:p}`Leppanen2018`. </b>\n",
    "\n",
    "Integrating spheres are field-based and you make the measurements on samples extracted from the snowpit face. The principle of the measurement is based on firing a laser at the snow sample, within a special reflective hollow sphere, where one side is filled by the snow sample, and measuring how much of the laser is reflected at a sensor at a known geometry. For more information, check out {cite:p}`Gallet2009`.  Most integrating sphere measurements are either made by a commercial firm (A2 Photonics) known as the [IceCube](https://a2photonicsensors.com/icecube-ssa/) or a version constructed at the University of Sherbrooke known as the IRIS {cite:p}`Montpetit2012`. These approaches are set up to measure SSA only. There were three of these at Grand Mesa - one of the Sherbrooke IRIS units, and two IceCubes, one from Finnish Meteorological Institute, and one from Ohio State University.\n",
    "\n",
    "<img src=\"images/SMP.png\" alt=\"ct-figure\" width=\"800px\">\n",
    "\n",
    "<b>Left: Megan Mason operates the SMP. Right: Closeup of the SMP sensor tip.</b>\n",
    "\n",
    "Snow micropenetrometers are also a field-based approach, but they do not require a snowpit, enabling far more observations to be made. Instead, an automated motor pushes a probe vertically downwards into the snowpack. The probe measures the force required to break snow microstructure, yielding a wealth of information. Snow density, specific surface area and correlation length can be retrieved; for background see {cite:p}`Lowe2012` and {cite:p}`Proksch2015`. The micropen effort at Grand Mesa was led by Boise State University. A key thing to be aware of is that differences in the various SMP instruments mean that the empirical relationship of {cite:p}`Proksch2015` will give quite poor results for the particular instrument used in SnowEx, as fully explained in {cite:p}`Calonne2020`.\n",
    "\n",
    "These methods are not the only ways to measure microstructure! There are several others not mentioned here, but not used at Grand Mesa 2020. Ask if interested.\n",
    "\n",
    "## SnowEx Microstructure Measurement Data Overview\n",
    "\n",
    "Of the three methods described above, microCT is by far the most expensive and most time consuming. Samples have to be transported back to the laboratory and the processing time requires a microCT machine. Thus the fewest CT sapmles are taken. \n",
    "\n",
    "The integrating spheres require a snowpit to be dug, so we have an intermediate number of them: ~100. \n",
    "\n",
    "The micropen measurements are by far the fastest to make, so a cross pattern of SMP measurements was made on orthogonal directions intersecting at the snowpit. There are thousands of SMP profiles from Grand Mesa 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the data\n",
    "\n",
    "We're going to do two things! First, we'll intercompare the three different integrating sphere instruments at four different pits where we had multiple instruments operating. We'd expect these data to be fairly self-consistent. Second, we'll compare all three methods (integrating sphere, SMP and microCT) at a single pit where we had all of these measurements present. Here especially with the SMP we would expect to need to intercalibrate the data to match local conditions; so far SSA has only been fit to SMP force measurements in one study, and we should assume we'll need a local calibration to get a tight fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules needed to access snowexsql: SnowEx field data database\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import LayerData, PointData\n",
    "from snowexsql.conversions import points_to_geopandas, query_to_geopandas\n",
    "\n",
    "# Modules needed to work with data\n",
    "import geoalchemy2.functions as gfunc\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#note - this cell does not return any output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Intercompare Integrating Sphere Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were three integrating spheres. The IRIS unit from University of Sherbrooke was operated by Celine Vargel. The IceCube unit from the Finnish Meteorological Institute was operated by Juha Lemmetyinen. And the IceCube unit from Ohio State was operated by Kehan Yang and Kate Hale. Carefully read the [documentation page](https://nsidc.org/data/SNEX20_SSA/versions/1) at NSIDC if you are interested in the data. If you are using the data for a project, please contact the authors and mention what you're doing - they'll appreciate it! Contact for SSA is Mike Durand (durand.8@osu.edu).\n",
    "\n",
    "See Micah's tutorial on datasets for more on this! Won't explain too much here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Grab all the equivalent diameter profiles\n",
    "q = session.query(LayerData).filter(LayerData.type == 'specific_surface_area')\n",
    "df = query_to_geopandas(q, engine)\n",
    "\n",
    "# End our database session to avoid hanging transactions\n",
    "session.close()\n",
    "\n",
    "df.head() #check out the results of the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to intercompare integrating spheres, we need to isolate only the sites that actually had multiple integrating spheres measuring the same snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the sites with equivalent diameter data (set reduces a list to only its unique entries)\n",
    "sites = df['site_id'].unique()\n",
    "\n",
    "# Store all site names that have multiple SSA instruments\n",
    "multi_instr_sites = []\n",
    "instruments = []\n",
    "\n",
    "for site in sites:\n",
    "\n",
    "    # Grab all the layers associated to this site\n",
    "    site_data = df.loc[df['site_id'] == site]\n",
    "\n",
    "    # Do a set on all the instruments used here\n",
    "    instruments_used = site_data['instrument'].unique()\n",
    "\n",
    "    if len(instruments_used) > 1:\n",
    "        multi_instr_sites.append(site)\n",
    "\n",
    "# Get a unqique list of SSA instruments that were colocated\n",
    "instruments = df['instrument'].unique()\n",
    "\n",
    "instruments #check out the list of instruments. note that the IceCube values are displayed as serial numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot all Integrating Sphere SSA profiles at all Multi-Integrating Sphere Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the subplot for each site for each instrument\n",
    "fig, axes = plt.subplots(1, len(multi_instr_sites), figsize=(4*len(multi_instr_sites), 8))\n",
    "\n",
    "# Establish plot colors unique to the instrument\n",
    "c = ['k', 'm', 'c']\n",
    "colors = {inst:c[i] for i,inst in enumerate(instruments)}\n",
    "\n",
    "# Loop over all the multi-instrument sites \n",
    "for i, site in enumerate(multi_instr_sites):\n",
    "    \n",
    "    # Grab the plot for this site\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Loop over all the instruments at this site\n",
    "    for instr in instruments:\n",
    "\n",
    "        # Grab our profile by site and instrument\n",
    "        ind = df['site_id'] == site \n",
    "        ind2 = df['instrument'] == instr\n",
    "        profile = df.loc[ind & ind2].copy()\n",
    "\n",
    "        # Don't plot it unless there is data\n",
    "        if len(profile.index) > 0:\n",
    "            \n",
    "            # Sort by depth so samples that are take out of order won't mess up the plot\n",
    "            profile = profile.sort_values(by='depth')\n",
    "            \n",
    "            # Layer profiles are always stored as strings. \n",
    "            profile['value'] = profile['value'].astype(float)\n",
    "            \n",
    "            # Plot our profile\n",
    "            ax.plot(profile['value'], profile['depth'], colors[instr], label=instr)\n",
    "   \n",
    "    # Labeling and plot style choices\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('SSA [m^2/kg]')\n",
    "    ax.set_ylabel('Height above snow-soil interface [cm]')\n",
    "    ax.set_title('Site {}'.format(site.upper()))\n",
    "    \n",
    "    # Set the x limits to show more detail\n",
    "    ax.set_xlim((8, 75))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pull the snowmicropenetrometer data and compute SSA\n",
    "\n",
    "The next step is to grab some SMP data to compare to. We're going to get the SMP at site 2N13, where we have a copule of SSA profiles from integrating spheres (as well as microCT data, to be looked at in the next step!). \n",
    "\n",
    "The SMP measurements for SnowEx 2020 GrandMesa were all made by Megan Mason. If you're interested in working with the SMP data, please carefully read the NSIDC [documentation page](https://nsidc.org/data/SNEX20_SMP/versions/1). If you're planning to work with the data, please reach out to the author; the contact is (Megan Mason meganmason491@u.boisestate.edu). If you use a profile, consider checking out the comments which are described in the [Excel sheet linked from the Technical References part of the NSIDC documentation](https://nsidc.org/sites/nsidc.org/files/technical-references/SNEX20_SMP_FieldNotes.xlsx), where there are some really useful comments. \n",
    "\n",
    "There are a few steps here, and one reason for that is just that the SMP data is quite large, and so the full-resolution SMP could not be included in Micah's database. The full resolution profile from SMP is resolved ever 1.25 mm! Instead, the SMP data in Micah's database is sampled to only every 100th datapoint, so it's every 12.5 cm. But the database is still very useful! What we'll do is use the database to find the right profile, then go and download that full resolution dataset from the NSIDC. Easy-peasey!\n",
    "\n",
    "As mentioned above, {cite:p}`Calonne2020` tested applying the relationship of {cite:p}`Proksch2015` and got quite poor results, explained them by the difference in hardware between generations of SMP instruments. We were unaware of that when designing the tutorial, and so set up use of the so-called official SMP processing repository, linked below, which has not yet been updated with the latest relationship. This would make a great project, as mentioned later!\n",
    "\n",
    "First up, we'll visualize the location of the SMP profiles, along with the snowpit location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = '2N13'\n",
    "engine_smp, session_smp = get_db(db_name)\n",
    "q_smp = session_smp.query(LayerData).filter(LayerData.type == 'force').filter(LayerData.site_id.contains(site) )\n",
    "df_smp = query_to_geopandas(q_smp, engine_smp)\n",
    "\n",
    "q_pit=session_smp.query(LayerData).filter(LayerData.type == 'hand_hardness').filter(LayerData.site_id.contains(site) )\n",
    "df_pit = query_to_geopandas(q_pit, engine_smp)\n",
    "\n",
    "session_smp.close()\n",
    "\n",
    "# Plot SMP profile locations with colored by the time they were taken using upside down triangles\n",
    "ax = df_smp.plot(column='time', cmap='jet', marker='v', label='SMP', figsize=(5,5), markersize=100, edgecolor='black')\n",
    "\n",
    "ax.plot(df_pit.easting, df_pit.northing, color='black', marker='s', markersize=15, label='Pit ({})'.format(site))\n",
    "\n",
    "# Add important labels\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Northing [m]')\n",
    "plt.suptitle('SMP Locations at Site {} Showing Acquisition Order'.format(site), fontsize=16)\n",
    "\n",
    "# Avoid using Scientific notation for coords.\n",
    "ax.ticklabel_format(style='plain', useOffset=False)\n",
    "ax.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, let's find the closest SMP profile to the snowpit, and then find the profile ID of that profile, which is in the comments in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find closest SMP profile to the pit\n",
    "\n",
    "# No profile is taken at the same time, so we grab all the unique times and sort them\n",
    "times = sorted(df_smp['time'].unique())\n",
    "\n",
    "nprofiles=len(times)\n",
    "\n",
    "ids=np.empty(nprofiles)\n",
    "\n",
    "p=0\n",
    "for t in times:\n",
    "    ind = df_smp['time'] == t\n",
    "    data = df_smp.loc[ind].copy()\n",
    "    ids[p]=data.iloc[0].id\n",
    "    p+=1\n",
    "    \n",
    "i_dists=df_smp['id'].isin(ids)\n",
    "\n",
    "df_smp_dists=df_smp.loc[i_dists]\n",
    "df_smp_dists=df_smp_dists.assign(dists=-1)\n",
    "df_smp_dists['dists']=np.sqrt((df_smp_dists['easting']-df_pit.iloc[0].easting)**2+(df_smp_dists['northing']-df_pit.iloc[0].northing)**2)\n",
    "\n",
    "    \n",
    "df_smp_dists.sort_values(by='dists')[['comments','dists']].head() #check out the list of profiles sorted by distance to pit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the id of the closest SMP profile is S19M1174.  I went to the [SMP page on NSIDC](https://nsidc.org/data/SNEX20_SMP/versions/1), and went to \"Download\" and searched for this ID, downloaded the profile, and then re-uploaded to my home directory here in the Jupyter hub. \n",
    "\n",
    "Ok next up, we have to compute SSA from the SMP data. For this, we'll use the \"snowmicropyn\" modules created by the Swiss SLF. You can read more about them [at this site](https://snowmicropyn.readthedocs.io/en/latest/). The software is a little out of date on Python versions; just ignore any warnings that pop up below! Also, the use of the  {cite:p}`Proksch2015` relationship is also out-of-date, as mentioned above. Getting it updated for use with this tutorial would make a perfect project!\n",
    "\n",
    "The next cell pulls in the needed modules, and then plots the profile of force measurements needed to break through the snow microstructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowmicropyn import Profile\n",
    "from snowmicropyn import proksch2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in some tutorial datasets \n",
    "!aws s3 sync --quiet s3://snowex-data/tutorial-data/microstructure/ /tmp/microstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Profile.load('/tmp/microstructure/SMP/SNEX20_SMP_S19M1174_2N13_20200206.PNT',)\n",
    "plt.plot(p.samples.distance, p.samples.force)\n",
    "# Prettify our plot a bit\n",
    "plt.title(p.name)\n",
    "plt.ylabel('Force [N]')\n",
    "plt.xlabel('Depth [mm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the entire SMP profile; this includes the part of the force profile that is above the snow surface, and thus needs to be removed, in order to apply calculations only to the snow (not the air!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the part of the profile that is in the snow (i.e. remove air)\n",
    "depth_surf=p.detect_surface()\n",
    "depth_ground=p.detect_ground()\n",
    "samples_snow=p.samples_within_distance(begin=depth_surf, end=depth_ground, relativize=False)\n",
    "samples_snow.distance-=depth_surf\n",
    "plt.plot(samples_snow.distance, samples_snow.force)\n",
    "plt.title(p.name)\n",
    "plt.ylabel('Force [N]')\n",
    "plt.xlabel('Depth [mm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above part of the profile is just the part that is in the snow. PLEASE NOTE that the automated functions are not infallible, and need to be used with care. For now, these need to be compared back to the notes and interpreted manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the actual calculation of SSA from the force data. It then displays the data and lets you see that there is now a column called SSA! Note that this function is \"proksch2015\". You can read about how it works in Martin Proksch's paper {cite:p}`Proksch2015`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call using the snowmicropyn library proksch2015\n",
    "p2015 = proksch2015.calc(p.samples) \n",
    "p2015.head() #check out the first few values of SSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read microCT data, and compare integrating sphere, SMP and CT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The microCT samples were extracted in the field and processed at CRREL by Lauren Farnsworth, and is not yet published at NSIDC. Please contact her with questions (lauren.b.farnsworth@usace.army.mil)!\n",
    "\n",
    "This module reads in microCT datafiles which are stored as text. Some additional data are available, showing the computer generated slices through the ice-air interface: contact Mike (durand.8@osu.edu) if you want to look at a subset of these data that Lauren has shared.\n",
    "\n",
    "Equivalent grain size is a useful quantity to compare: because it's proportional to 1/SSA, and because after a point as you increase SSA more and more, all fine-grained snow acts more-or-less the same (converging to e.g. the \"fine-grained\" curve in Figure 1, above), we'll look at equivalent diameter instead of SSA in this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_CT_txt_files import read_CT_txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read micro CT for 2N13\n",
    "data_dir='/tmp/microstructure/microCT/txt/'\n",
    "[SSA_CT,height_min,height_max]=read_CT_txt_files(data_dir)\n",
    "\n",
    "SSA_CT #check out the SSA values read in from MicroCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data integrating sphere data for 2N13 and plot it \n",
    "site='2N13'\n",
    "engine_is, session_is = get_db(db_name)\n",
    "q_is = session_is.query(LayerData).filter(LayerData.type == 'specific_surface_area').filter(LayerData.site_id.contains(site) )\n",
    "df_is = query_to_geopandas(q_is, engine_is)\n",
    "instruments_site = df_is['instrument'].unique()\n",
    "\n",
    "# Loop over all the integrating sphere instruments at this site. plot equivalent diameter\n",
    "fig,ax = plt.subplots()\n",
    "for instr in instruments_site:\n",
    "\n",
    "    # Grab our profile by site and instrument\n",
    "    ind = df['site_id'] == site \n",
    "    ind2 = df['instrument'] == instr\n",
    "    profile = df.loc[ind & ind2].copy()\n",
    "\n",
    "    # Don't plot it unless there is data\n",
    "    if len(profile.index) > 0:\n",
    "\n",
    "        # Sort by depth so samples that are take out of order won't mess up the plot\n",
    "        profile = profile.sort_values(by='depth')\n",
    "\n",
    "        # Layer profiles are always stored as strings. \n",
    "        profile['value'] = 6/917/profile['value'].astype(float)*1000\n",
    "\n",
    "        # Plot our profile\n",
    "        ax.plot(profile['value'], profile['depth'], colors[instr], label=instr)\n",
    "        \n",
    "#All that's left to do is plot the CT and the SMP and label the plot!\n",
    "ax.plot(6/917/SSA_CT*1000,height_min,label='microCT')        #CT data\n",
    "\n",
    "ax.plot(6/917/p2015.P2015_ssa*1000,(max(p2015.distance)-p2015.distance)/10,label='SMP') #SMP data\n",
    "\n",
    "# Labeling and plot style choices\n",
    "ax.legend()\n",
    "ax.set_xlabel('Equivalent diameter, mm')\n",
    "ax.set_ylabel('Height above snow-soil interface [cm]')\n",
    "ax.set_title('Site {}'.format(site.upper()))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, so the datasets are so very different, with the SMP being by far the most different. Comparing with {cite:p}`Calonne2020` shows that the SMP is off in the same direction as diagnosed in that paper. Thus, the difference is most likely due to the difference in SMP instruments. Dr. Mel Sandells of Northumbria University has a github branch of the SMP software SnowMicropyn that has the newer fit relationship integrated in the software. It would be a nice project to loop in Mel's branch with this notebook and see how well things compare to SnowEx data. I'd be happy to help anyone interested get rolling on that!\n",
    "\n",
    "There's also significant differences between the microCT and the two integrating spheres. This is science - sometimes when we start intercomparing these quantities, we do not get a perfect match. This would also be a fascinating thing to explore in a Hackweek project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the ways that you could imagine connecting microstructure measurements to other quantities would be with the SWESARR radar data. Although the radar data does seem to have some orthorectification issues that haven't been fully worked out, I can imagine these being worked around by careful choice of places you match up the microstructure to the radar. Note that places that are shallower tend to have larger D<sub>eq</sub> and vice versa, and the spatial variability in SSA was fairly low in general in Grand Mesa 2020, so looking at multiple SSA vs radar samples might not yield a great correlation. But you never know, could be fun to try! Generally speaking, we don't expect a ton of impact of the microstructure on L-band (UAVSAR), but it would be interesting to explore that.\n",
    "\n",
    "One thing that could be of great value is to calibrate the SMP estimates of SSA to the integrating spheres. If you're interested in doing that, do reach out first. This could be a really interesting thing to explore!\n",
    "\n",
    "It might also be interesting to compare the data to hand hardness measured in the snowpit, and to traditional hand lens measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
