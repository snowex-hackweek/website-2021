{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorrect-appendix",
   "metadata": {},
   "source": [
    "# Pit Matrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recreational-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "\n",
    "#database imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import SiteData, ImageData, LayerData, PointData\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-relation",
   "metadata": {},
   "source": [
    "## Distinguish pits by vegetation coverage: \n",
    "- treeless (0% tree cover)\n",
    "- sparse (1-30% tree cover)\n",
    "- dense (31-100% tree cover)\n",
    "\n",
    "*vegetation classes assigned based on optical imagery: tree density map, Nov. 2010 WorldView-2 Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_veg_class(site_id):\n",
    "    \n",
    "    # Classifying by vegetation coverage \n",
    "    veg_class = {'treeless':[1, 2, 3], 'sparse':[4, 5, 6], 'dense':[7, 8, 9]}\n",
    "   \n",
    "    vclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric():\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        for k,v in veg_class.items():\n",
    "\n",
    "            if class_id in v:\n",
    "                vclass = k \n",
    "                \n",
    "    return vclass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-allergy",
   "metadata": {},
   "source": [
    "### Distinguish pits by snow depth classes: \n",
    "- shallow (<90cm)\n",
    "- medium (90-122cm)\n",
    "- deep (>122cm)\n",
    "\n",
    "*depth classes assigned based on 2017 snow depth lidar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cellular-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_class(site_id):\n",
    "    # Classifying by expected depth \n",
    "    depth_class = {'shallow':[1, 4, 7], 'medium':[2, 5, 8], 'deep':[3, 6, 9]} \n",
    "   \n",
    "    dclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric(): #for the outlier TS site\n",
    "        class_id = int(class_id) #cast as integer\n",
    "\n",
    "        for k,v in depth_class.items(): #for the key, value pairs in the dict listed above:\n",
    "\n",
    "            if class_id in v:\n",
    "                dclass = k \n",
    "\n",
    "    return dclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dated-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>type</th>\n",
       "      <th>units</th>\n",
       "      <th>surveyors</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geom</th>\n",
       "      <th>depth</th>\n",
       "      <th>site_id</th>\n",
       "      <th>value</th>\n",
       "      <th>veg_class</th>\n",
       "      <th>depth_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4272</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.039987</td>\n",
       "      <td>-108.191917</td>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9C17</td>\n",
       "      <td>124.5</td>\n",
       "      <td>dense</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4273</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.039987</td>\n",
       "      <td>-108.191917</td>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9C17</td>\n",
       "      <td>207.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4274</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.039987</td>\n",
       "      <td>-108.191917</td>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9C17</td>\n",
       "      <td>230.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4275</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.039987</td>\n",
       "      <td>-108.191917</td>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9C17</td>\n",
       "      <td>258.5</td>\n",
       "      <td>dense</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4276</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.039987</td>\n",
       "      <td>-108.191917</td>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9C17</td>\n",
       "      <td>258.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2356</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.014367</td>\n",
       "      <td>-108.141578</td>\n",
       "      <td>POINT (747487.000 4322259.000)</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3S47</td>\n",
       "      <td>256.5</td>\n",
       "      <td>treeless</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2357</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.014367</td>\n",
       "      <td>-108.141578</td>\n",
       "      <td>POINT (747487.000 4322259.000)</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3S47</td>\n",
       "      <td>281.0</td>\n",
       "      <td>treeless</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2358</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.014367</td>\n",
       "      <td>-108.141578</td>\n",
       "      <td>POINT (747487.000 4322259.000)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3S47</td>\n",
       "      <td>299.5</td>\n",
       "      <td>treeless</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2359</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.014367</td>\n",
       "      <td>-108.141578</td>\n",
       "      <td>POINT (747487.000 4322259.000)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3S47</td>\n",
       "      <td>262.5</td>\n",
       "      <td>treeless</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>Grand Mesa</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>131</td>\n",
       "      <td>None</td>\n",
       "      <td>density</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39.016119</td>\n",
       "      <td>-108.141750</td>\n",
       "      <td>POINT (747466.000 4322453.000)</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2S46</td>\n",
       "      <td>253.0</td>\n",
       "      <td>treeless</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2822 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       site_name        date    id instrument     type units surveyors  \\\n",
       "0     Grand Mesa  2020-01-30  4272       None  density  None      None   \n",
       "1     Grand Mesa  2020-01-30  4273       None  density  None      None   \n",
       "2     Grand Mesa  2020-01-30  4274       None  density  None      None   \n",
       "3     Grand Mesa  2020-01-30  4275       None  density  None      None   \n",
       "4     Grand Mesa  2020-01-30  4276       None  density  None      None   \n",
       "...          ...         ...   ...        ...      ...   ...       ...   \n",
       "2817  Grand Mesa  2020-01-29  2356       None  density  None      None   \n",
       "2818  Grand Mesa  2020-01-29  2357       None  density  None      None   \n",
       "2819  Grand Mesa  2020-01-29  2358       None  density  None      None   \n",
       "2820  Grand Mesa  2020-01-29  2359       None  density  None      None   \n",
       "2821  Grand Mesa  2020-02-04   131       None  density  None      None   \n",
       "\n",
       "       latitude   longitude                            geom  depth site_id  \\\n",
       "0     39.039987 -108.191917  POINT (743040.000 4324967.000)   75.0    9C17   \n",
       "1     39.039987 -108.191917  POINT (743040.000 4324967.000)   65.0    9C17   \n",
       "2     39.039987 -108.191917  POINT (743040.000 4324967.000)   55.0    9C17   \n",
       "3     39.039987 -108.191917  POINT (743040.000 4324967.000)   45.0    9C17   \n",
       "4     39.039987 -108.191917  POINT (743040.000 4324967.000)   35.0    9C17   \n",
       "...         ...         ...                             ...    ...     ...   \n",
       "2817  39.014367 -108.141578  POINT (747487.000 4322259.000)   42.0    3S47   \n",
       "2818  39.014367 -108.141578  POINT (747487.000 4322259.000)   32.0    3S47   \n",
       "2819  39.014367 -108.141578  POINT (747487.000 4322259.000)   22.0    3S47   \n",
       "2820  39.014367 -108.141578  POINT (747487.000 4322259.000)   12.0    3S47   \n",
       "2821  39.016119 -108.141750  POINT (747466.000 4322453.000)   79.0    2S46   \n",
       "\n",
       "      value veg_class depth_class  \n",
       "0     124.5     dense        deep  \n",
       "1     207.0     dense        deep  \n",
       "2     230.0     dense        deep  \n",
       "3     258.5     dense        deep  \n",
       "4     258.0     dense        deep  \n",
       "...     ...       ...         ...  \n",
       "2817  256.5  treeless        deep  \n",
       "2818  281.0  treeless        deep  \n",
       "2819  299.5  treeless        deep  \n",
       "2820  262.5  treeless        deep  \n",
       "2821  253.0  treeless      medium  \n",
       "\n",
       "[2822 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "result = session.query(LayerData.type).distinct().all()\n",
    "\n",
    "qry = session.query(LayerData).filter(LayerData.type=='density')\n",
    "\n",
    "# Form our dataframe from the query \n",
    "df = query_to_geopandas(qry, engine)\n",
    "df['value'] = df['value'].astype(float) #cast the value as a float (they are strings)\n",
    " \n",
    "# parse snow pit data by the veg/depth matrix\n",
    "df['veg_class'] = [parse_veg_class(i) for i in df['site_id']] #run the parse_veg function for every site_id\n",
    "df['depth_class'] = [parse_depth_class(i) for i in df['site_id']] #run the parse_depth funciton for every site_id\n",
    "\n",
    "# # Show off our df \n",
    "# df.plot()\n",
    "\n",
    "df.columns\n",
    "col_list = ['site_name', 'date', 'id', 'instrument', 'type', 'units', 'surveyors', 'latitude',\n",
    "       'longitude', 'geom','depth', 'site_id', 'value', 'veg_class', 'depth_class']\n",
    "df = df[col_list]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "impressed-dover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       75.0\n",
       "1       65.0\n",
       "2       55.0\n",
       "3       45.0\n",
       "4       35.0\n",
       "        ... \n",
       "2817    42.0\n",
       "2818    32.0\n",
       "2819    22.0\n",
       "2820    12.0\n",
       "2821    79.0\n",
       "Name: depth, Length: 2822, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "banned-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all of the unique site ids \n",
    "len(df['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fatty-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "veg_class\n",
       "dense       50\n",
       "sparse      39\n",
       "treeless    60\n",
       "Name: site_name, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make df with only 153 rows using site_id.unique\n",
    "gb = df.groupby(['site_id', 'veg_class'])\n",
    "#gb = df.groupby('site_id')\n",
    "gb['site_name'].count().groupby(\"veg_class\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = df[['veg_class', 'depth_class']].groupby(df['site_id']).groups\n",
    "# gb = df.groupby(['veg_class', 'site_id']).count()\n",
    "# gb = df.groupby(['site_id']).count()\n",
    "df['veg_class'].groupby('veg_class').count()\n",
    "\n",
    "# print(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "numerical-glasgow",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e4d8a61dcf2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'veg_class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "df['site_id'].unique().groupby('veg_class').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ready-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veg_class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dense</th>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sparse</th>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treeless</th>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           site_id\n",
       "veg_class         \n",
       "dense          923\n",
       "sparse         801\n",
       "treeless      1017"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['veg_class', 'site_id']].groupby('veg_class').count() #table I like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['veg_class', 'counter']].groupby(\"veg_class\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['veg_class', 'depth']].groupby(\"veg_class\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot depth classes\n",
    "df[['depth_class', 'counter']].groupby(\"depth_class\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['depth_class', 'depth']].groupby(\"depth_class\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pit_id = df['site_id'] + df['date'].astype(str)\n",
    "df['unique_pit_id'] = unique_pit_id\n",
    "\n",
    "# groups = df[['unique_pit_id', 'veg_class', 'counter']].groupby('veg_class').groups\n",
    "print(df.loc[df.veg_class == \"treeless\"].groupby(unique_pit_id).mean()['depth'].mean())\n",
    "print(df.loc[df.veg_class == \"sparse\"].groupby(unique_pit_id).mean()['depth'].mean())\n",
    "print(df.loc[df.veg_class == \"dense\"].groupby(unique_pit_id).mean()['depth'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df.veg_class == \"treeless\"][\"unique_pit_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df.veg_class == \"sparse\"][\"unique_pit_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df.veg_class == \"dense\"][\"unique_pit_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "result = session.query(SiteData).distinct().all()\n",
    "\n",
    "\n",
    "qry = session.query(SiteData)\n",
    "\n",
    "# # Form our dataframe from the query \n",
    "df = query_to_geopandas(qry, engine)\n",
    "# df['value'] = np.float64(df.value)   # these come out as strings ... \n",
    "# df['counter'] = 1 \n",
    "\n",
    "# df['veg_class'] = [parse_veg_class(i) for i in df['site_id']]\n",
    "# df['depth_class'] = [parse_depth_class(i) for i in df['site_id']]\n",
    "\n",
    "# # Show off our df \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['veg_class'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-rental",
   "metadata": {},
   "source": [
    "PLOT: #1 Density\n",
    "\n",
    "  - depth (cm) vs. density (kg/m3) for snow depth classes\n",
    "  - 3 colors: shallow (r), medium (g), deep (b)\n",
    "  - vertical bars to show the 10cm measurement increments (see ../images)  \n",
    "  - time period -- (hmm, all? single day? 1 week avg?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "empty-plaza",
   "metadata": {},
   "source": [
    "PLOT: #2 Temperature\n",
    "\n",
    "  - depth (cm) vs. temperature (C) for snow depth classes\n",
    "  - 3 colors: shallow (r), medium (g), deep (b)\n",
    "  - x-axis is -10 to 0 (see ../images)  \n",
    "  - time period -- (hmm, all? single day? 1 week avg?)\n",
    "  - could plot all pits with light gray line (or group by depth classes in a light/transparent color) and then take the avg. of 'shallow', 'medium', 'deep' and plot with a bold color line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-trunk",
   "metadata": {},
   "source": [
    "PLOT: #3\n",
    "  - do something with stratigraphy here....still thinking on that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_id = '5N34'\n",
    "# dclass = None \n",
    "# class_id = site_id[0]\n",
    "\n",
    "# # (k for k,v in dict.iteritems() if v == value)\n",
    "\n",
    "# for k,v in depth_class.items():\n",
    "#     (k for k,v in class_id)\n",
    "    \n",
    "    \n",
    "#     print(k)\n",
    "# #     print('v:', v)\n",
    "# # #     if class_id = v\n",
    "# # #     dclass = k\n",
    "# # #     print(dclass)\n",
    "# # print(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_veg_class(site_id):\n",
    "#     # Classifying by vegetation coverage \n",
    "#     veg_class = {'treeless':[1, 3], 'sparse':[4, 6], 'dense':[7, 9]}\n",
    "   \n",
    "#     vclass = None \n",
    "    \n",
    "#     class_id = site_id[0]\n",
    "    \n",
    "#     if class_id.isnumeric():\n",
    "#         class_id = int(class_id)\n",
    "\n",
    "#         for k,v in veg_class.items():\n",
    "\n",
    "#             if class_id >= v[0] and class_id <= v[1]:\n",
    "#                 vclass = k \n",
    "                \n",
    "#     return vclass\n",
    "\n",
    "# def parse_depth_class(site_id):\n",
    "#     # Classifying by expected depth \n",
    "#     depth_class = {'shallow':[1, 4, 7], 'medium':[2, 5, 8], 'deep':[3, 6, 9]} #[1:3:9]\n",
    "   \n",
    "#     dclass = None \n",
    "    \n",
    "#     class_id = site_id[0]\n",
    "    \n",
    "#     if class_id.isnumeric(): #for the outlier TS site\n",
    "#         class_id = int(class_id) #cast as integer\n",
    "\n",
    "#         for k,v in depth_class.items(): #for the key, value pairs in the dict listed above:\n",
    "\n",
    "#             if class_id = v[0] or v[1] or v[2]:\n",
    "#                 dclass = k \n",
    "#                 break\n",
    "\n",
    "#     return dclass \n",
    "\n",
    "# site_id = '5N34'\n",
    "# dclass = None \n",
    "# class_id = site_id[0]\n",
    "\n",
    "# # (k for k,v in dict.iteritems() if v == value)\n",
    "\n",
    "# for k,v in depth_class.items():\n",
    "#     (k for k,v in class_id)\n",
    "    \n",
    "    \n",
    "#     print(k)\n",
    "# #     print('v:', v)\n",
    "# # #     if class_id = v\n",
    "# # #     dclass = k\n",
    "# # #     print(dclass)\n",
    "# # print(class_id)\n",
    "\n",
    "# # load the database\n",
    "# db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "# engine, session = get_db(db_name)\n",
    "\n",
    "# result = session.query(LayerData.type).distinct().all()\n",
    "# print(result)\n",
    "\n",
    "# qry = session.query(LayerData).filter(LayerData.type=='density')\n",
    "\n",
    "# # Form our dataframe from the query \n",
    "# df = query_to_geopandas(qry, engine)\n",
    "\n",
    "# # Form a handy lambda for performant ops in df's\n",
    "# veg_class_lambda = lambda row: parse_veg_class(row['site_id'])\n",
    "# df['veg_class'] = df.apply(veg_class_lambda, axis=1)\n",
    "\n",
    "# # Show off our df \n",
    "# df.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
