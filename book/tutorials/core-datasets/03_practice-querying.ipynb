{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "urban-steal",
   "metadata": {},
   "source": [
    "# Practice Querying the Snowexsql Database\n",
    "\n",
    "(12 minutes)\n",
    "\n",
    "Learning Objectives:  \n",
    "- First taste of the database!\n",
    "- Code snippets to extract and prep data.\n",
    "- Generate ideas for project pitches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "\n",
    "#database imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "print('snowexsql database successfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-dollar",
   "metadata": {},
   "source": [
    "## Snow Pit data are contained in the following data tables:  \n",
    "\n",
    "_PointData_  = pit ruler depths, SWE.  \n",
    "_LayerData_  = density, temperature, stratigraphy, etc.  \n",
    "_SiteData_   = siteID, airTemp, vegetation, visit time, weather, etc.  \n",
    "\n",
    "### Example 1: Let's find all the pits that overlap with an airborne sensor of interest!\n",
    "\n",
    "First, it would be helpful to know, which of the airborne sensors are part of the database, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the session using .surveyors() to generate a list\n",
    "qry = session.query(ImageData.surveyors)\n",
    "\n",
    "# Locate all that are distinct\n",
    "airborne_sensors_list = session.query(ImageData.surveyors).distinct().all()\n",
    "\n",
    "print('list of airborne sensors by \"surveyor\" name: \\n', airborne_sensors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-immune",
   "metadata": {},
   "source": [
    "#### 1a). Unsure of the flight date, but know which sensor you'd like to overlap with, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airborne sensor from list above\n",
    "sensor = 'UAVSAR team, JPL'\n",
    "\n",
    "# Form on the Images table that returns Raster collection dates\n",
    "qry = session.query(ImageData.date)\n",
    "\n",
    "# Filter for UAVSAR data\n",
    "qry = qry.filter(ImageData.surveyors == sensor)\n",
    "\n",
    "# Grab the unique dates\n",
    "qry = qry.distinct()\n",
    "\n",
    "# Execute the query \n",
    "dates = qry.all() \n",
    "\n",
    "# Clean up the dates \n",
    "dates = [d[0] for d in dates] \n",
    "dlist = [str(d) for d in dates]\n",
    "dlist = \", \".join(dlist)\n",
    "print('%s flight dates are: %s' %(sensor, dlist))\n",
    "\n",
    "# Find all the snow pits done on these days\n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(dates))\n",
    "\n",
    "# Return a geopandas df\n",
    "df = query_to_geopandas(qry, engine)\n",
    "\n",
    "# View the returned pandas dataframe!\n",
    "print(df.head())\n",
    "\n",
    "# Close your session to avoid hanging transactions\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-namibia",
   "metadata": {},
   "source": [
    "#### 1b). Want to select an exact flight date match? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a day from the list of dates\n",
    "dt = dates[0] \n",
    "\n",
    "# Find all the snow pits done on these days \n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date == dt)\n",
    "\n",
    "# Return a geopandas df\n",
    "df_exact = query_to_geopandas(qry, engine)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_exact), sensor, dt))\n",
    "\n",
    "# View snows pits that align with first UAVSAR date\n",
    "df_exact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-printer",
   "metadata": {},
   "source": [
    "#### 1c). Want to select a range of dates near the flight date? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a date range to query on either side of our chosen day \n",
    "date_range = [dt + i * datetime.timedelta(days=1) for i in [-1, 0, 1]]\n",
    "\n",
    "# Find all the snow pits done on these days \n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(date_range))\n",
    "\n",
    "# Return a geopandas df\n",
    "df_range = query_to_geopandas(qry, engine)\n",
    "\n",
    "# Clean up dates (for print statement only)\n",
    "dlist = [str(d) for d in date_range]\n",
    "dlist = \", \".join(dlist)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_range), sensor, dlist))\n",
    "\n",
    "# View snow pits that are +/- 1 day of the first UAVSAR flight date\n",
    "df_range.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-redhead",
   "metadata": {},
   "source": [
    "#### 1d). Have a known date that you wish to select data for, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the data that was collected on 2-12-2020\n",
    "dt = datetime.date(2020, 2, 12)\n",
    "\n",
    "#--------------- Point Data -----------------------------------\n",
    "# Grab all Point data instruments from our date\n",
    "point_instruments = session.query(PointData.instrument).filter(PointData.date == dt).distinct().all()\n",
    "point_type = session.query(PointData.type).filter(PointData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up point data (i.e. remove tuple)\n",
    "point_instruments = [p[0] for p in point_instruments]\n",
    "point_instruments = \", \".join(point_instruments)\n",
    "point_type = [p[0] for p in point_type]\n",
    "point_type = \", \".join(point_type)\n",
    "print('Point data on %s are: %s, with the following list of parameters: %s' %(str(dt), point_instruments, point_type))\n",
    "\n",
    "#--------------- Layer Data -----------------------------------\n",
    "# Grab all Layer data instruments from our date\n",
    "layer_instruments = session.query(LayerData.instrument).filter(LayerData.date == dt).distinct().all()\n",
    "layer_type = session.query(LayerData.type).filter(LayerData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up layer data \n",
    "layer_instruments = [l[0] for l in layer_instruments if l[0] is not None]\n",
    "layer_instruments = \", \".join(layer_instruments)\n",
    "layer_type = [l[0] for l in layer_type]\n",
    "layer_type = \", \".join(layer_type)\n",
    "print('\\nLayer Data on %s are: %s, with the following list of parameters: %s' %(str(dt), layer_instruments, layer_type))\n",
    "\n",
    "#--------------- Image Data -----------------------------------\n",
    "# Grab all Image data instruments from our date\n",
    "image_instruments = session.query(ImageData.instrument).filter(ImageData.date == dt).distinct().all()\n",
    "image_type = session.query(ImageData.type).filter(ImageData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up image data (i.e. remove tuple)\n",
    "image_instruments = [i[0] for i in image_instruments]\n",
    "image_instruments = \", \".join(image_instruments)\n",
    "image_type = [i[0] for i in image_type]\n",
    "image_type = \", \".join(image_type)\n",
    "print('\\nImage Data on %s are: %s, with the following list of parameters: %s' %(str(dt), image_instruments, image_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-america",
   "metadata": {},
   "source": [
    "### Nice work, almost done here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-insured",
   "metadata": {},
   "source": [
    "## Classify pit data based on the depth and vegetation matrix\n",
    "### Example 2: \n",
    "\n",
    "#### 2a).Distinguish pits by vegetation coverage: \n",
    "- treeless (0% tree cover)\n",
    "- sparse (1-30% tree cover)\n",
    "- dense (31-100% tree cover)\n",
    "\n",
    "*vegetation classes assigned based on optical imagery: tree density map, Nov. 2010 WorldView-2 Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_veg_class(site_id):\n",
    "    \n",
    "    '''\n",
    "    This function parses snow pit data into three vegetation classes:\n",
    "        - 1). Treeless, 2). Sparce, and 3). Dense\n",
    "        \n",
    "    It uses a python dictionary where:\n",
    "        (k) keys: are the vegetation classes\n",
    "        (v) values: are the first digit in the pitID assignment\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Classifying by vegetation coverage \n",
    "    veg_class = {'treeless':[1, 2, 3], 'sparse':[4, 5, 6], 'dense':[7, 8, 9]}\n",
    "     \n",
    "    vclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric():\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        for k,v in veg_class.items():\n",
    "\n",
    "            if class_id in v: #if the first digit in the site_id is 'v' assign it to the corresponding 'k'\n",
    "                vclass = k \n",
    "                \n",
    "    return vclass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-likelihood",
   "metadata": {},
   "source": [
    "#### 2b). Distinguish pits by snow depth classes: \n",
    "- shallow (<90cm)\n",
    "- medium (90-122cm)\n",
    "- deep (>122cm)\n",
    "\n",
    "*depth classes assigned based on 2017 ASO snow depth lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_class(site_id):\n",
    "    \n",
    "    '''\n",
    "    This function parses snow pit data into three depth classes:\n",
    "        - 1). Shallow, 2). Medium, and 3). Deep\n",
    "        \n",
    "    It uses a python dictionary where:\n",
    "        (k) keys: are the depth classes\n",
    "        (v) values: are the first digit in the pitID assignment\n",
    "      \n",
    "  \n",
    "    '''\n",
    "        \n",
    "    # Classifying by 2017 depth \n",
    "    depth_class = {'shallow':[1, 4, 7], 'medium':[2, 5, 8], 'deep':[3, 6, 9]} \n",
    "   \n",
    "    dclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric(): #for the outlier TS site\n",
    "        class_id = int(class_id) #cast as integer\n",
    "\n",
    "        for k,v in depth_class.items(): #for the key, value pairs in the dict listed above:\n",
    "\n",
    "            if class_id in v: #if the first digit in the site_id is 'v' assign it to the corresponding 'k'\n",
    "                dclass = k \n",
    "\n",
    "    return dclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Query for Layer Data\n",
    "result = session.query(LayerData.type).distinct().all()\n",
    "\n",
    "# Filter for density data\n",
    "qry = session.query(LayerData).filter(LayerData.type=='density')\n",
    "\n",
    "# Form our dataframe from the query \n",
    "df = query_to_geopandas(qry, engine)\n",
    "df['value'] = df['value'].astype(float)  #cast the value as a float (they are strings)\n",
    "\n",
    "# Parse snow pit data by the veg/depth matrix\n",
    "df['veg_class'] = [parse_veg_class(i) for i in df['site_id']] #run the parse_veg function for every site_id\n",
    "df['depth_class'] = [parse_depth_class(i) for i in df['site_id']] #run the parse_depth function for every site_id\n",
    "\n",
    "# Select columns of interest\n",
    "col_list = ['site_id', 'date', 'type', 'latitude',\n",
    "       'longitude', 'depth', 'value', 'veg_class', 'depth_class']\n",
    "df = df[col_list]\n",
    "\n",
    "# View a sample --> notice parsed veg_class and depth_class columns were added!\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by site-id to count classes\n",
    "gb = df.groupby(['site_id', 'veg_class', 'depth_class'])\n",
    "\n",
    "print(gb['site_id'].count().groupby('veg_class').count())\n",
    "print('\\n')\n",
    "print(gb['site_id'].count().groupby('depth_class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-antarctica",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for veg_class\n",
    "df.boxplot(column='value', by='veg_class', fontsize='large')\n",
    "plt.ylabel('Density kg/m3')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for depth_class\n",
    "df.boxplot(column='value', by='depth_class')\n",
    "plt.ylabel('Density kg/m3')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great for debugging especially when trying different queries\n",
    "session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close your session to avoid hanging transactions\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
